{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chekosworld/Aitopia/blob/main/intro_to_colab_ml_notebook_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqtm6YMB9S_H"
      },
      "source": [
        "# Google Colab y Python - Introducción al Machine Learning\n",
        "Este notebook está diseñado para que aprendas los conceptos básicos necesarios\n",
        "para el procesamiento de datos en proyectos de machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5oYeSr19S_I"
      },
      "source": [
        "## 1. Sintaxis básica de Python\n",
        "En esta celda, aprenderemos los fundamentos de Python:\n",
        "- Cómo imprimir texto en la pantalla\n",
        "- Cómo crear variables y asignarles valores\n",
        "- Diferentes tipos de datos: números enteros, decimales y texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2UDud-J9S_J",
        "outputId": "824a7ad1-a9fc-43ff-f614-25d6ef54893b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Hola, Colab!\n"
          ]
        }
      ],
      "source": [
        "# 1. Sintaxis básica\n",
        "print(\"¡Hola, Colab!\")\n",
        "x = 10\n",
        "y = 3.14\n",
        "nombre = \"Basilio\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV9zWb-y9S_J"
      },
      "source": [
        "## 2. Tipos de datos en Python\n",
        "Aquí veremos cómo identificar el tipo de datos de una variable:\n",
        "- Usamos la función `type()` para conocer el tipo de dato\n",
        "- Veremos tipos como `int` (entero), `float` (decimal) y `str` (texto)\n",
        "\n",
        "**Resumen**:\n",
        "- Escalares: Valores individuales, utilizados para representar características o medidas simples.\n",
        "- Listas: Colecciones de datos, flexibles y modificables, útiles para almacenar series de datos.\n",
        "- Tuplas: Colecciones de datos inmutables, usadas para datos constantes.\n",
        "- Vectores: Estructuras unidimensionales que representan características o puntos en el espacio.\n",
        "- Matrices: Tablas bidimensionales, esenciales para cálculos matriciales.\n",
        "- Tensores: Extensiones de matrices a múltiples dimensiones, útiles en machine learning.\n",
        "- DataFrames: Tablas etiquetadas, el formato más utilizado para el análisis de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHypW4iC9S_K",
        "outputId": "336736e0-1ed2-414b-f849-5d91a0bc304f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# 2. Tipos de datos\n",
        "print(type(x))\n",
        "print(type(y))\n",
        "print(type(nombre))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 1 Estructuras de Datos en Python para Data Science\n",
        "Esta lección cubre la creación y uso de las estructuras de datos más comunes en Python que son fundamentales para el análisis y procesamiento de datos en ciencia de datos: escalares, listas, tuplas, vectores, matrices y dataframes."
      ],
      "metadata": {
        "id": "G6bU8-EgPcrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1.1. Escalares\n",
        "Un escalar es una variable que almacena un solo valor. En Data Science, los escalares pueden representar características individuales como el precio de un producto o el valor de una medida."
      ],
      "metadata": {
        "id": "BJuwgoimPq2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un escalar\n",
        "escalar = 5\n",
        "print(\"Escalar:\", escalar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwaZfeRFPo91",
        "outputId": "46b42d4b-8b37-48fe-ebe9-3f9b5fe43b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escalar: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.2. Listas\n",
        "Las listas en Python son colecciones ordenadas de elementos. Se usan en Data Science para almacenar conjuntos de datos simples o series de valores.\n",
        "\n",
        "**Aplicación en Data Science:** Las listas se utilizan para almacenar muestras de datos o características individuales de un conjunto de datos."
      ],
      "metadata": {
        "id": "oNF6L2e-Pyyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de una lista\n",
        "lista = [1, 2, 3, 4, 5]\n",
        "print(\"Lista:\", lista)\n",
        "\n",
        "# Acceder a un elemento de la lista\n",
        "print(\"Primer elemento:\", lista[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxVR-2yjPx3Z",
        "outputId": "2a543034-65a3-4bf5-8be4-2fe8e6bbce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista: [1, 2, 3, 4, 5]\n",
            "Primer elemento: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.3. Tuplas\n",
        "Las tuplas son similares a las listas, pero son inmutables, es decir, no se pueden modificar una vez creadas. En Data Science, se utilizan para almacenar datos que no deben cambiar, como coordenadas o parámetros de un modelo."
      ],
      "metadata": {
        "id": "6HwwsnbWQN-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de una tupla\n",
        "tupla = (1, 2, 3)\n",
        "print(\"Tupla:\", tupla)\n",
        "\n",
        "# Acceder a un elemento de la tupla\n",
        "print(\"Segundo elemento de la tupla:\", tupla[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5eiap8QJfb",
        "outputId": "285fcef8-72da-4d4a-c008-2002f4dbe7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tupla: (1, 2, 3)\n",
            "Segundo elemento de la tupla: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.4. Vectores\n",
        "Un vector es una estructura de datos que contiene una secuencia de números. En Data Science, los vectores se usan para representar características de un conjunto de datos o puntos en el espacio.\n",
        "\n",
        "Vamos a crear un vector usando NumPy, una librería muy popular en Data Science."
      ],
      "metadata": {
        "id": "qp1O2vJ0QUhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un vector (array de una dimensión)\n",
        "vector = np.array([1, 2, 3, 4, 5])\n",
        "print(\"Vector:\", vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y52fiZRTQZp3",
        "outputId": "a19eb52b-257c-46a2-c3d6-83baecddf8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector: [1 2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.5. Matrices\n",
        "Una matriz es una estructura bidimensional, es decir, contiene filas y columnas. En Data Science, las matrices se utilizan para representar conjuntos de datos tabulares o transformaciones matemáticas.\n",
        "\n",
        "**Aplicación en Data Science**: Las matrices son esenciales para cálculos matriciales en machine learning y álgebra lineal."
      ],
      "metadata": {
        "id": "Jxoxoih-Qcxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de una matriz (array de dos dimensiones)\n",
        "matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(\"Matriz:\\n\", matriz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUR2ggktQlKf",
        "outputId": "5274d305-414c-41ee-977e-d0d0145b7ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.6. Matrices de diferentes dimensiones\n",
        "Además de matrices 2D, puedes trabajar con matrices de más dimensiones, llamadas tensores.\n",
        "\n",
        "**Aplicación en Data Science**: Los tensores son comunes en redes neuronales y otras aplicaciones de machine learning de alta dimensión.\n",
        "\n"
      ],
      "metadata": {
        "id": "tCi9hydtQtBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de una matriz 3D (tensor)\n",
        "tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(\"Matriz 3D (Tensor):\\n\", tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwCj2F5PQ1p3",
        "outputId": "21424f7d-9fe5-47c1-de0b-c42ea31c6d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz 3D (Tensor):\n",
            " [[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[5 6]\n",
            "  [7 8]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.7. DataFrames\n",
        "Un DataFrame es una estructura de datos similar a una tabla en pandas, con etiquetas para las filas y columnas. Es el formato más utilizado para manipular y analizar datos en Data Science.\n",
        "\n",
        "**Aplicación en Data Science**: Los DataFrames permiten la manipulación eficiente de datos tabulares, como limpieza de datos, transformación y análisis estadístico."
      ],
      "metadata": {
        "id": "BluYAIhOQ5jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame simple\n",
        "datos = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
        "         'Edad': [23, 30, 25],\n",
        "         'Ciudad': ['Madrid', 'Barcelona', 'Sevilla']}\n",
        "\n",
        "df = pd.DataFrame(datos)\n",
        "print(\"DataFrame:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4VsBYfRlef",
        "outputId": "edcb8e91-f888-40b7-a3d6-96e3f03d8852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame:\n",
            "   Nombre  Edad     Ciudad\n",
            "0    Ana    23     Madrid\n",
            "1   Luis    30  Barcelona\n",
            "2  Pedro    25    Sevilla\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz0cAoCx9S_K"
      },
      "source": [
        "## 3. Navegación de Datos en DataFrames\n",
        "En esta sección, aprenderemos a manejar DataFrames, una de las estructuras más importantes para trabajar con datos en ciencia de datos. Veremos cómo crear DataFrames a partir de diferentes fuentes de datos (Excel, JSON, TXT, SQL), cómo acceder a elementos específicos dentro de ellos, y cómo extraer secciones para crear listas y diccionarios.\n",
        "\n",
        "En esta lección, aprenderemos:\n",
        "\n",
        "- Cómo crear DataFrames a partir de distintas fuentes de datos.\n",
        "- Cómo acceder a elementos específicos dentro de un DataFrame.\n",
        "- Cómo extraer secciones de un DataFrame para crear listas y diccionarios.\n",
        "\n",
        "¡Sigue practicando con tus propios datasets para dominar la manipulación de datos con DataFrames!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1. Crear un DataFrame a partir de diferentes fuentes de datos\n",
        "Los DataFrames pueden crearse a partir de diversas fuentes de datos, como archivos de Excel, JSON, TXT y bases de datos SQL. Usaremos la librería pandas para ello.\n",
        "\n",
        "**Aplicación en Data Science**: Los DataFrames nos permiten importar y manipular grandes cantidades de datos desde diferentes formatos para analizarlos de manera eficiente."
      ],
      "metadata": {
        "id": "yttWNDjxbqqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo Excel\n",
        "df_excel = pd.read_excel('archivo.xlsx')\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo JSON\n",
        "df_json = pd.read_json('archivo.json')\n",
        "\n",
        "# Ejemplo: Crear un DataFrame desde un archivo TXT (archivo delimitado por comas o tabulaciones)\n",
        "df_txt = pd.read_csv('archivo.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "9-kdPgCWbucl",
        "outputId": "be81d4df-97df-4ebb-f95d-f02506c934d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'archivo.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e28fbabb146d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ejemplo: Crear un DataFrame desde un archivo Excel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_excel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'archivo.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Ejemplo: Crear un DataFrame desde un archivo JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archivo.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: Crear un DataFrame desde una consulta SQL\n",
        "#import sqlite3\n",
        "#conn = sqlite3.connect('database.db')\n",
        "#df_sql = pd.read_sql_query(\"SELECT * FROM tabla\", conn)"
      ],
      "metadata": {
        "id": "R0V4nf6rceVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: Crear un DataFrame desde una consulta web (no es webscrapping)\n",
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# URL donde esta el archivo CSV\n",
        "url = 'https://www.inegi.org.mx/contenidos/programas/enoe/datosabiertos/enoe.zip'\n",
        "zip_filename = '/content/file.zip'\n",
        "\n",
        "# Bajar el archivo a la sesion de colab\n",
        "response = requests.get(url)\n",
        "with open(zip_filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    # Extract all the contents into the /content directory\n",
        "    zip_ref.extractall('/content')\n",
        "\n",
        "# Información guardada en un dataframe\n",
        "data =  pd.read_csv(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lcga4WMlcieZ",
        "outputId": "7e953635-c9cd-4f52-d53a-cfb90b2ab1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-27efe70c3e15>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Bajar el archivo a la sesion de colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2. Acceder a elementos específicos en un DataFrame\n",
        "Un DataFrame es como una tabla, y podemos acceder a sus filas, columnas o celdas de forma específica.\n",
        "\n",
        "**Aplicación en Data Science**: Acceder a elementos específicos en un DataFrame permite examinar detalles de los datos o realizar transformaciones en partes concretas del conjunto de datos."
      ],
      "metadata": {
        "id": "DKpVNTLuc7fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un DataFrame simple para los ejemplos\n",
        "datos = {'Nombre': ['Ana', 'Luis', 'Pedro'],\n",
        "         'Edad': [23, 30, 25],\n",
        "         'Ciudad': ['Madrid', 'Barcelona', 'Sevilla']}\n",
        "\n",
        "df = pd.DataFrame(datos)\n",
        "\n",
        "# Acceder a una columna\n",
        "print(\"Columna 'Nombre':\\n\", df['Nombre'])\n",
        "\n",
        "# Acceder a una fila por su índice\n",
        "print(\"Fila con índice 1:\\n\", df.iloc[1])\n",
        "\n",
        "# Acceder a una celda específica (fila 0, columna 'Ciudad')\n",
        "print(\"Celda en fila 0, columna 'Ciudad':\", df.at[0, 'Ciudad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idhx_MovdabC",
        "outputId": "d5ae5759-9475-4b6a-ffbf-e76efb8dcc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna 'Nombre':\n",
            " 0      Ana\n",
            "1     Luis\n",
            "2    Pedro\n",
            "Name: Nombre, dtype: object\n",
            "Fila con índice 1:\n",
            " Nombre         Luis\n",
            "Edad             30\n",
            "Ciudad    Barcelona\n",
            "Name: 1, dtype: object\n",
            "Celda en fila 0, columna 'Ciudad': Madrid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3. Tomar secciones de un DataFrame para crear listas y diccionarios\n",
        "A menudo, en Data Science, necesitamos extraer subconjuntos de datos para realizar análisis específicos o convertirlos en otros formatos.\n",
        "\n",
        "**Aplicación en Data Science:** Extraer listas o diccionarios de un DataFrame nos permite manipular o analizar partes específicas de los datos de manera más flexible."
      ],
      "metadata": {
        "id": "uc2lXsGvdfMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer una columna como lista\n",
        "nombres = df['Nombre'].tolist()\n",
        "print(\"Columna 'Nombre' como lista:\", nombres)\n",
        "\n",
        "# Extraer una fila como diccionario\n",
        "fila_como_diccionario = df.iloc[1].to_dict()\n",
        "print(\"Fila 1 como diccionario:\", fila_como_diccionario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iic2PjvcdoJQ",
        "outputId": "afaa5611-e60a-42d5-dc01-d0018e88e3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna 'Nombre' como lista: ['Ana', 'Luis', 'Pedro']\n",
            "Fila 1 como diccionario: {'Nombre': 'Luis', 'Edad': 30, 'Ciudad': 'Barcelona'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utN2oy9D9S_K"
      },
      "source": [
        "## 4. Entendimiento de los datos en matrices\n",
        "Aquí aprenderemos a obtener información básica sobre nuestros datos:\n",
        "- Usaremos `info()` para conocer la estructura de nuestra DataFrame\n",
        "- Usaremos `describe()` para obtener estadísticas descriptivas\n",
        "- Verificaremos si hay valores nulos en nuestro DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSDCenKZ9S_K",
        "outputId": "d301dcce-0608-4376-80bf-b2f4ea41d0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Nombre  3 non-null      object\n",
            " 1   Edad    3 non-null      int64 \n",
            " 2   Ciudad  3 non-null      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 200.0+ bytes\n",
            "None\n",
            "            Edad\n",
            "count   3.000000\n",
            "mean   26.000000\n",
            "std     3.605551\n",
            "min    23.000000\n",
            "25%    24.000000\n",
            "50%    25.000000\n",
            "75%    27.500000\n",
            "max    30.000000\n",
            "Nombre    0\n",
            "Edad      0\n",
            "Ciudad    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 4. Entendimiento de los datos en matrices\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5an-H6Ek9S_L"
      },
      "source": [
        "## 5. Limpieza de datos\n",
        "En esta sección, aprenderemos a manejar valores faltantes:\n",
        "- Crearemos un DataFrame con valores nulos\n",
        "- Usaremos `fillna()` para reemplazar los valores nulos con la media de cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i8i9ARy9S_L",
        "outputId": "a0414154-15a9-47ca-f00e-2459eb386ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B    C\n",
            "0  1.0  4.0  8.5\n",
            "1  2.0  5.0  8.0\n",
            "2  1.5  6.0  9.0\n"
          ]
        }
      ],
      "source": [
        "# 5. Limpieza de datos\n",
        "df_con_nulos = pd.DataFrame({'A': [1, 2, np.nan], 'B': [4, np.nan, 6], 'C': [np.nan, 8, 9]})\n",
        "df_con_nulos.fillna(df_con_nulos.mean(), inplace=True)\n",
        "print(df_con_nulos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5yX8KIZ9S_L"
      },
      "source": [
        "## 6. Escalado de características\n",
        "Aquí aprenderemos a escalar nuestros datos:\n",
        "- Usaremos MinMaxScaler para transformar nuestros datos\n",
        "- Veremos cómo los datos se escalan al rango [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3W-WGf29S_L",
        "outputId": "925ee379-3f92-407c-a2b7-c4e7564a73d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos originales:\n",
            " [[1 2]\n",
            " [2 4]\n",
            " [3 6]\n",
            " [4 8]]\n",
            "Datos escalados:\n",
            " [[0.         0.        ]\n",
            " [0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667]\n",
            " [1.         1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# 6. Escalado de características\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "datos = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
        "scaler = MinMaxScaler()\n",
        "datos_escalados = scaler.fit_transform(datos)\n",
        "print(\"Datos originales:\\n\", datos)\n",
        "print(\"Datos escalados:\\n\", datos_escalados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYE1kZHY9S_L"
      },
      "source": [
        "## 7. Codificación de variables categóricas\n",
        "En esta sección, aprenderemos a manejar datos categóricos:\n",
        "- Crearemos un DataFrame con variables categóricas\n",
        "- Usaremos `get_dummies()` para convertir estas variables en formato numérico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eli4xN69S_L",
        "outputId": "856ad06c-0a67-4d0b-b93c-11e013918f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Azul  Color_Rojo  Color_Verde  Tamaño_Grande  Tamaño_Mediano  \\\n",
            "0       False        True        False           True           False   \n",
            "1       False       False         True          False           False   \n",
            "2        True       False        False          False            True   \n",
            "\n",
            "   Tamaño_Pequeño  \n",
            "0           False  \n",
            "1            True  \n",
            "2           False  \n"
          ]
        }
      ],
      "source": [
        "# 7. Codificación de variables categóricas\n",
        "df_categorico = pd.DataFrame({'Color': ['Rojo', 'Verde', 'Azul'], 'Tamaño': ['Grande', 'Pequeño', 'Mediano']})\n",
        "df_codificado = pd.get_dummies(df_categorico)\n",
        "print(df_codificado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LvHXSt09S_L"
      },
      "source": [
        "## 8. División de datos\n",
        "Aquí aprenderemos a dividir nuestros datos en conjuntos de entrenamiento y prueba:\n",
        "- Usaremos `train_test_split` para dividir nuestros datos\n",
        "- Veremos cómo se separan los datos en características (X) y etiquetas (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IS7vMBT9S_M",
        "outputId": "46ae85f5-4713-4834-c90e-9289f8e081d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento:\n",
            " [[4 8]\n",
            " [1 2]\n",
            " [3 6]]\n",
            "Datos de prueba:\n",
            " [[2 4]]\n"
          ]
        }
      ],
      "source": [
        "# 8. División de datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
        "y = np.array([0, 1, 0, 1])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Datos de entrenamiento:\\n\", X_train)\n",
        "print(\"Datos de prueba:\\n\", X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aSz2E089S_M"
      },
      "source": [
        "## 9. Estructuras de control\n",
        "En esta sección, aprenderemos sobre estructuras de control básicas en Python:\n",
        "- Usaremos una declaración `if-else` para tomar decisiones basadas en condiciones\n",
        "- Utilizaremos un bucle `for` para repetir acciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI3TARXm9S_M",
        "outputId": "3bb275d7-e786-4091-b9df-700a01fa9c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 es mayor que 5\n",
            "Iteración: 0\n",
            "Iteración: 1\n",
            "Iteración: 2\n",
            "Iteración: 3\n",
            "Iteración: 4\n"
          ]
        }
      ],
      "source": [
        "# 9. Estructuras de control\n",
        "if x > 5:\n",
        "    print(f\"{x} es mayor que 5\")\n",
        "else:\n",
        "    print(f\"{x} es menor o igual que 5\")\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Iteración: {i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLbnCU-g9S_M"
      },
      "source": [
        "## 10. Funciones\n",
        "Finalmente, aprenderemos sobre funciones en Python:\n",
        "- Definiremos una función simple que suma dos números\n",
        "- Llamaremos a la función y imprimiremos el resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogd_bG479S_M",
        "outputId": "ccfd9075-4061-449c-9640-5df65814187b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La suma es: 15\n"
          ]
        }
      ],
      "source": [
        "# 10. Funciones\n",
        "def sumar(a, b):\n",
        "    return a + b\n",
        "resultado = sumar(10, 5)\n",
        "print(\"La suma es:\", resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11.1. Convertir Texto, Audio e Imágenes a DataFrames para Modelos de Machine Learning\n",
        "En esta sección, aprenderemos cómo convertir diferentes tipos de datos, como texto, audio e imágenes, en un formato que pueda ser utilizado por modelos de machine learning. Utilizaremos pandas para trabajar con DataFrames, así como bibliotecas adicionales según sea necesario para procesar cada tipo de dato.\n",
        "\n",
        "**En esta lección, aprendemos**:\n",
        "\n",
        "- Cómo convertir texto a DataFrames utilizando técnicas de vectorización.\n",
        "- Cómo convertir audio a DataFrames extrayendo características.\n",
        "- Cómo convertir imágenes a DataFrames utilizando la representación de píxeles.\n",
        "\n",
        "Estos pasos son esenciales para preparar datos no estructurados para su uso en modelos de machine learning. ¡Sigue explorando y experimentando con diferentes tipos de datos!"
      ],
      "metadata": {
        "id": "cB6O-5dXem2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11.1. Convertir Texto a DataFrames\n",
        "El texto puede ser procesado y convertido en un DataFrame para su uso en modelos de machine learning. Para ello, utilizaremos técnicas como la tokenización y la creación de características.\n",
        "\n",
        "**Aplicación en Data Science:** La conversión de texto a un formato numérico permite que los modelos de machine learning comprendan el contenido textual y realicen tareas como clasificación o análisis de sentimientos."
      ],
      "metadata": {
        "id": "IgMNIV7ifLbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Ejemplo de datos de texto\n",
        "documentos = [\n",
        "    \"El aprendizaje automático es fascinante.\",\n",
        "    \"Los modelos de machine learning son poderosos.\",\n",
        "    \"La ciencia de datos combina estadística y programación.\"\n",
        "]\n",
        "\n",
        "# Convertir el texto en un DataFrame\n",
        "df_texto = pd.DataFrame(documentos, columns=['Texto'])\n",
        "\n",
        "# Vectorización: convertir texto a vectores numéricos\n",
        "vectorizer = CountVectorizer()\n",
        "X_texto = vectorizer.fit_transform(df_texto['Texto']).toarray()\n",
        "\n",
        "# Crear un nuevo DataFrame con las características\n",
        "df_vectorizado_texto = pd.DataFrame(X_texto, columns=vectorizer.get_feature_names_out())\n",
        "print(\"DataFrame de texto vectorizado:\\n\", df_vectorizado_texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnjA5yUQd6kL",
        "outputId": "4bb55d11-7d32-4189-8c6c-2dd2111ef5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de texto vectorizado:\n",
            "    aprendizaje  automático  ciencia  combina  datos  de  el  es  estadística  \\\n",
            "0            1           1        0        0      0   0   1   1            0   \n",
            "1            0           0        0        0      0   1   0   0            0   \n",
            "2            0           0        1        1      1   1   0   0            1   \n",
            "\n",
            "   fascinante  la  learning  los  machine  modelos  poderosos  programación  \\\n",
            "0           1   0         0    0        0        0          0             0   \n",
            "1           0   0         1    1        1        1          1             0   \n",
            "2           0   1         0    0        0        0          0             1   \n",
            "\n",
            "   son  \n",
            "0    0  \n",
            "1    1  \n",
            "2    0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11.2. Convertir Audio a DataFrames\n",
        "El audio también puede ser convertido a un formato adecuado para machine learning. Normalmente, esto implica extraer características del audio, como espectrogramas o MFCC (coeficientes cepstrales en las frecuencias Mel).\n",
        "\n",
        "**Aplicación en Data Science**: Al convertir audio en características, podemos entrenar modelos para tareas como reconocimiento de voz o clasificación de sonidos."
      ],
      "metadata": {
        "id": "hSvaGka8fYyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# Cargar un archivo de audio y extraer características\n",
        "# audio_path = 'archivo_audio.wav'\n",
        "# y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "# Para este ejemplo, generamos un array de características ficticias\n",
        "# características = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "# características = características.T  # Transponer para que cada fila sea una observación\n",
        "\n",
        "# Ejemplo de características ficticias (por ejemplo, 5 muestras de 13 coeficientes)\n",
        "caracteristicas = np.random.rand(5, 13)  # Simulación de 5 muestras de características\n",
        "\n",
        "# Crear un DataFrame con las características de audio\n",
        "df_audio = pd.DataFrame(caracteristicas, columns=[f'MFCC_{i+1}' for i in range(caracteristicas.shape[1])])\n",
        "print(\"DataFrame de características de audio:\\n\", df_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEr8ZkYCfdMZ",
        "outputId": "07c132f2-e6af-4357-b25c-6e9e1a73f6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de características de audio:\n",
            "      MFCC_1    MFCC_2    MFCC_3    MFCC_4    MFCC_5    MFCC_6    MFCC_7  \\\n",
            "0  0.473363  0.612204  0.043229  0.444660  0.695470  0.282199  0.834772   \n",
            "1  0.660286  0.357719  0.091478  0.003319  0.976615  0.640469  0.692416   \n",
            "2  0.845178  0.575377  0.557245  0.290725  0.510969  0.296072  0.704457   \n",
            "3  0.771713  0.484508  0.029932  0.496622  0.331256  0.518103  0.786260   \n",
            "4  0.320778  0.916599  0.406055  0.005895  0.998306  0.334539  0.817272   \n",
            "\n",
            "     MFCC_8    MFCC_9   MFCC_10   MFCC_11   MFCC_12   MFCC_13  \n",
            "0  0.680923  0.928238  0.096759  0.223515  0.397742  0.431472  \n",
            "1  0.833587  0.667173  0.286006  0.025500  0.842909  0.986306  \n",
            "2  0.111359  0.918280  0.960521  0.159887  0.073944  0.570790  \n",
            "3  0.453097  0.976903  0.114308  0.536624  0.025483  0.487110  \n",
            "4  0.145916  0.049414  0.048068  0.195243  0.686967  0.326781  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11.3. Convertir Imágenes a DataFrames\n",
        "Las imágenes se pueden convertir en DataFrames extrayendo características, como los píxeles o utilizando técnicas de extracción de características como SIFT o HOG.\n",
        "\n",
        "**Aplicación en Data Science**: La conversión de imágenes a un formato tabular permite que los modelos de machine learning puedan realizar tareas como clasificación de imágenes, detección de objetos o segmentación."
      ],
      "metadata": {
        "id": "3-vOSnNFfntF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_sample_image\n",
        "import numpy as np\n",
        "\n",
        "# Cargar una imagen de muestra\n",
        "china = load_sample_image(\"china.jpg\")\n",
        "\n",
        "# Redimensionar la imagen usando Pillow (PIL) en lugar de NumPy\n",
        "from PIL import Image\n",
        "china_resized = np.array(Image.fromarray(china).resize((100, 100)))\n",
        "\n",
        "# Aplanar la imagen en un array\n",
        "pixels = china_resized.reshape(-1, 3)  # Convertir a un array 2D\n",
        "\n",
        "# Crear un DataFrame a partir de los píxeles de la imagen\n",
        "df_imagen = pd.DataFrame(pixels, columns=['Rojo', 'Verde', 'Azul'])\n",
        "print(\"DataFrame de píxeles de la imagen:\\n\", df_imagen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN2iJKo3fv_4",
        "outputId": "0070b860-28f2-4c4f-ff5b-d17894a54db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de píxeles de la imagen:\n",
            "       Rojo  Verde  Azul\n",
            "0      174    201   231\n",
            "1      174    202   232\n",
            "2      174    203   232\n",
            "3      177    204   234\n",
            "4      177    204   234\n",
            "...    ...    ...   ...\n",
            "9995     3      7     3\n",
            "9996     4      6     2\n",
            "9997     4      6     1\n",
            "9998     5      6     3\n",
            "9999    16     18    13\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2xyAChRZfhy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1v3jfmGUfTq6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}